{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e22c0d3",
   "metadata": {},
   "source": [
    "## Installation instructions\n",
    " - uh...hopefully you have torch and transformers already bc i dont remember how i did this myself lol\n",
    " - for the model:\n",
    "     - (install lfs, i used homebrew, perhaps you can do it another way\n",
    "     - in command line type:\n",
    "         - `git lfs install`\n",
    "     - then clone the pegasus-xsum repo/or whatever model to try\n",
    "         - `GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/google/pegasus-xsum`\n",
    "     - note that the prepended thing is for you to not download the big files from the repo (i think)\n",
    "     - cd into the cloned repo (should be named `pegasus-xsum`)\n",
    "     - re-run the following command\n",
    "         - `git lfs install` (maybe prepend the `GIT_LFS` thing from above bc without doing that, it did take 17 years)\n",
    "     - after that finishes you should see ^^ `Git LFS initialized`. then you can run the things below vvv\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bcd6775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch and transformers already installed\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "# imports main dependencies\n",
    "# tokenizer converts sentences to tokens\n",
    "# other class allows for us to see the model\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99f8a58",
   "metadata": {},
   "source": [
    "1. Creating our tokenizer for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d17f88c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the \"pegasus-xsum\" string should be the path to the cloned repo ^^\n",
    "tokenizer_model = PegasusTokenizer.from_pretrained(\"pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2ea4e8",
   "metadata": {},
   "source": [
    "Tokenizer is now imported, the `from_pretrained` method allows us to import a pre-trained model. In this case, it is the `google/pegasus-xsum`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088e1ede",
   "metadata": {},
   "source": [
    "2. Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffa77252",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model = PegasusForConditionalGeneration.from_pretrained(\"pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2afb59",
   "metadata": {},
   "source": [
    "Using the `PegasusConditionalGeneration` class is used to load the model. Again the `from_pretrained`, allows us to import the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd58df3",
   "metadata": {},
   "source": [
    "4. Now create a variable called `text` and add text to it.\n",
    "The text below is the abstract from an ACM journal of the paper titled *A Framework for Adversarially Robust Streaming Algorithms*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0b6df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"We investigate the adversarial robustness of streaming algorithms. In this context, an algorithm is considered robust if its performance guarantees hold even if the stream is chosen adaptively by an adversary that observes the outputs of the algorithm along the stream and can react in an online manner. While deterministic streaming algorithms are inherently robust, many central problems in the streaming literature do not admit sublinear-space deterministic algorithms; on the other hand, classical space-efficient randomized algorithms for these problems are generally not adversarially robust. This raises the natural question of whether there exist efficient adversarially robust (randomized) streaming algorithms for these problems.In this work, we show that the answer is positive for various important streaming problems in the insertion-only model, including distinct elements and more generally Fp-estimation, Fp-heavy hitters, entropy estimation, and others. For all of these problems, we develop adversarially robust (1+ε)-approximation algorithms whose required space matches that of the best known non-robust algorithms up to a poly(log n, 1/ε) multiplicative factor (and in some cases even up to a constant factor). Towards this end, we develop several generic tools allowing one to efficiently transform a non-robust streaming algorithm into a robust one in various scenarios.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1386ba87",
   "metadata": {},
   "source": [
    "5. Apply tokenizer. This stores the token representation of the text, using the `tokenizer_model` to tokenize our texts. The `truncation = True` allows the model to truncate our texts into a size that is suitable for the model. The `return_tensors` argument tells the model to use tensors from `PyTorch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef12600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer_model(text, truncation=True, padding='longest',\n",
    "                        return_tensors = \"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6c868ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  184,  5731,   109, 68623, 40851,   113,  5383,  8970,   107,   222,\n",
       "           136,  2956,   108,   142,  7680,   117,  1341,  5076,   175,   203,\n",
       "           637,  8353,  1137,   254,   175,   109,  3871,   117,  2590, 14831,\n",
       "           445,   141,   142, 43363,   120, 40591,   109, 15487,   113,   109,\n",
       "          7680,   466,   109,  3871,   111,   137,  8602,   115,   142,   338,\n",
       "          2403,   107,  1041, 64897,  5383,  8970,   127, 20115,  5076,   108,\n",
       "           223,  2056,   743,   115,   109,  5383,  4413,   171,   146,  4884,\n",
       "          2672, 29371,   121,  8544, 64897,  8970,   206,   124,   109,   176,\n",
       "           561,   108,  6925,   501,   121, 12687, 24374,  8970,   118,   219,\n",
       "           743,   127,  1813,   146, 68623,   445,  5076,   107,   182, 10015,\n",
       "           109,   710,   906,   113,   682,   186,  3201,  1882, 68623,   445,\n",
       "          5076,   143, 43049,  3792,   158,  5383,  8970,   118,   219,   743,\n",
       "           107,   315,   136,   201,   108,   145,   403,   120,   109,  1140,\n",
       "           117,  1259,   118,   623,   356,  5383,   743,   115,   109, 23768,\n",
       "           121,  6026,   861,   108,   330,  5057,  1811,   111,   154,  1813,\n",
       "          1091,  1379,   121, 95381,   108,  1091,  1379,   121, 22564, 39847,\n",
       "           108, 55255, 16627,   108,   111,   536,   107,   321,   149,   113,\n",
       "           219,   743,   108,   145,  1070, 68623,   445,  5076,  4653,  1754,\n",
       "           105,   158,   121, 28648, 49687,  8970,  1843,   656,   501,  3637,\n",
       "           120,   113,   109,   229,   606,   609,   121,  3882, 46109,  8970,\n",
       "           164,   112,   114,  8517,   741,  9096,  3178,   108,   305,   191,\n",
       "           105,   158,  1546,  1379, 13131,  8757,  2634,   143,   526,   115,\n",
       "           181,  1145,   254,   164,   112,   114,  3357,  2634,   250, 33519,\n",
       "           136,   370,   108,   145,  1070,   500,  5511,   977,  2063,   156,\n",
       "           112,  4680,  4780,   114,   609,   121,  3882, 46109,  5383,  7680,\n",
       "           190,   114,  5076,   156,   115,   623,  7743,   107,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view tokens -- can't really translate tokens, so not sure what the number means\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97ee6c4",
   "metadata": {},
   "source": [
    "6. Summarize text. `**tokens` unpacks the tokens and passess them into the model. The `**` are simply adding the `input_ids` and `attention_mask` present in the results below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca770021",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = loaded_model.generate(**tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fdb3d8",
   "metadata": {},
   "source": [
    "This is the summary results in tokens, which represent the output tensors. Decoding the values will help us make sense of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c94df979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,   222,   136,   201,   108,   145,  1070, 68623,   445,  5076,\n",
       "          4653,  1754,   105,   158,   121, 28648, 49687,  8970,  1843,   656,\n",
       "           501,  3637,   120,   113,   109,   229,   606,   609,   121,  3882,\n",
       "         46109,  8970,   164,   112,   114,  8517,   741,  9096,  3178,   108,\n",
       "           305,   191,   105,   158,  1546,  1379, 13131,  8757,  2634,   107,\n",
       "             1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68d9754",
   "metadata": {},
   "source": [
    "7. Decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f73a500b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In this work, we develop adversarially robust (1+ ⁇ )-approximation algorithms whose required space matches that of the best known non-robust algorithms up to a poly(log n, 1/ ⁇ ) multiplicative factor.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_model.decode(summary[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4bf4b9",
   "metadata": {},
   "source": [
    "The results above show that the results are in a nested list. We only need the first result, hence why indexed at 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a23fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
