1 Introduction. Learning in phrase alignment models generally requires computing either Viterbi phrase alignments or expectations of alignment links. For some restricted combinatorial spaces of alignments—those that arise in ITG-based phrase models (Cherry and Lin, 2007) or local distortion models (Zens et al., 2004)—inference can be accomplished using polynomial time dynamic programs. However, for more permissive models such as Marcu and Wong (2002) and DeNero et al. (2006), which operate over the full space of bijective phrase alignments (see below), no polynomial time algorithms for exact inference have been exhibited. Indeed, Marcu and Wong (2002) conjectures that none exist. In this paper, we show that Viterbi inference in this full space is NP-hard, while computing expectations is #P-hard. On the other hand, we give a compact formulation of Viterbi inference as an integer linear program (ILP). Using this formulation, exact solutions to the Viterbi search problem can be found by highly optimized, general purpose ILP solvers. While ILP is of course also NP-hard, we show that, empirically, exact solutions are found very quickly for most problem instances. In an experiment intended to illustrate the practicality of the ILP approach, we show speed and search accuracy results for aligning phrases under a standard phrase translation model.
2 Phrase Alignment Problems. Rather than focus on a particular model, we describe four problems that arise in training phrase alignment models. A sentence pair consists of two word sequences, e and f. A set of phrases {eij} contains all spans eij from between-word positions i to j of e. A link is an aligned pair of phrases, denoted (eij, fkl).' Let a weighted sentence pair additionally include a real-valued function 0 : {eij}x{fkl} —* R, which scores links. 0(eij, fkl) can be sentence-specific, for example encoding the product of a translation model and a distortion model for (eij, fkl). We impose no additional restrictions on 0 for our analysis. An alignment is a set of links. Given a weighted sentence pair, we will consider the space of bijective phrase alignments A: those a C {eij} x {fkl} that use each word token in exactly one link. We first define the notion of a partition: UiSi = T means Si are pairwise disjoint and cover T. Then, we can formally define the set of bijective phrase alignments: Both the conditional model of DeNero et al. (2006) and the joint model of Marcu and Wong (2002) operate in A, as does the phrase-based decoding framework of Koehn et al. (2003). For a weighted sentence pair (e, f, φ), let the score of an alignment be the product of its link scores: Four related problems involving scored alignments arise when training phrase alignment models. OPTIMIZATION, O: Given (e, f, φ), find the highest scoring alignment a. DECISION, D: Given (e, f, φ), decide if there is an alignment a with φ(a) > 1. O arises in the popular Viterbi approximation to EM (Hard EM) that assumes probability mass is concentrated at the mode of the posterior distribution over alignments. D is the corresponding decision problem for O, useful in analysis. EXPECTATION, £: Given a weighted sentence pair (e, f, φ) and indices i, j, k,l, compute Ea φ(a) over all a E A such that (eij, fkl) E a. SUM, S: Given (e, f, φ), compute EaEA φ(a). £ arises in computing sufficient statistics for re-estimating phrase translation probabilities (Estep) when training models. The existence of a polynomial time algorithm for £ implies a polynomial time algorithm for S, because A = U;e1 1 Ukf |0 Ulf=k+1 {a : (e0j, fkl) E a, a E A}.
3 Complexity of Inference in A. For the space A of bijective alignments, problems £ and O have long been suspected of being NP-hard, first asserted but not proven in Marcu and Wong (2002). We give a novel proof that O is NP-hard, showing that D is NP-complete by reduction from SAT, the boolean satisfiability problem. This result holds despite the fact that the related problem of finding an optimal matching in a weighted bipartite graph (the ASSIGNMENT problem) is polynomialtime solvable using the Hungarian algorithm. A reduction proof of NP-completeness gives a construction by which a known NP-complete problem can be solved via a newly proposed problem. From a SAT instance, we construct a weighted sentence pair for which alignments with positive score correspond exactly to the SAT solutions. Since SAT is NPcomplete and our construction requires only polynomial time, we conclude that D is NP-complete.2 SAT: Given vectors of boolean variables v = (v) and propositional clauses3 C = (C), decide whether there exists an assignment to v that simultaneously satisfies each clause in C. For a SAT instance (v, C), we construct f to contain one word for each clause, and e to contain several copies of the literals that appear in those clauses. φ scores only alignments from clauses to literals that satisfy the clauses. The crux of the construction lies in ensuring that no variable is assigned both true and false. The details of constructing such a weighted sentence pair wsp(v, C) = (e, f, φ), described below, are also depicted in figure 1. Then, we set φ(·, ·) = 0 everywhere except: Proof. The score implies that f aligns using all oneword phrases and Vai E a, 0(ai) = 1. By condition 4, each fassign(v) aligns to all v� or all v in e. Then, assign each v to true if fassign(v) aligns to all v, and false otherwise. By condition 3, each C must align to a satisfying literal, while condition 4 assures that all available literals are consistent with this assignment to v, which therefore satisfies C. Claim 2. If (v, C) is satisfiable, then wsp(v, C) has an alignment a with 0(a) = 1. Proof. We construct such an alignment a from the satisfying assignment v. For each C, we choose a satisfying literal E consistent with the assignment. Align fC to the first available E token in e if the corresponding v is true, or the last if v is false. Align each fassign(v) to all remaining literals for v. Claims 1 and 2 together show that D is NPcomplete, and therefore that O is NP-hard. With another construction, we can show that S is #Phard, meaning that it is at least as hard as any #Pcomplete problem. #P is a class of counting problems related to NP, and #P-hard problems are NPhard as well.
COUNTING PERFECT MATCHINGS, CPM. Given a bipartite graph G with 2n vertices, count the number of matchings of size n. For a bipartite graph G with edge set E = {(vj, vl)}, we construct e and f with n words each, and set 0(ej−1 j, fl−1 l) = 1 and 0 otherwise. The number of perfect matchings in G is the sum S for this weighted sentence pair. CPM is #P-complete (Valiant, 1979), so S (and hence £) is #P-hard.
4 Solving the Optimization Problem. Although O is NP-hard, we present an approach to solving it using integer linear programming (ILP). Marcu and Wong (2002) describes an approximation to O. Given a weighted sentence pair, high scoring phrases are linked together greedily to reach an initial alignment. Then, local operators are applied to hill-climb A in search of the maximum a. This procedure also approximates £ by collecting weighted counts as the space is traversed. DeNero et al. (2006) instead proposes an exponential-time dynamic program to systematically explore A, which can in principle solve either O or £. In practice, however, the space of alignments has to be pruned severely using word alignments to control the running time of EM. Notably, neither of these inference approaches offers any test to know if the optimal alignment is ever found. Furthermore, they both require small data sets due to computational expense. We cast O as an ILP problem, for which many optimization techniques are well known. First, we introduce binary indicator variables ai,j,k,l denoting whether (eij, fkl) ∈ a. Furthermore, we introduce binary indicators ei,j and fk,l that denote whether some (eij, ·) or (·, fkl) appears in a, respectively. Finally, we represent the weight function 0 as a weight vector in the program: wi,j,k,l = log 0(eij, fkl). Now, we can express an integer program that, when optimized, will yield the optimal alignment of our weighted sentence pair. Sentences per hour on a four-core server Frequency of optimal solutions found Frequency of e-optimal solutions found Using an off-the-shelf ILP solver,4 we were able to quickly and reliably find the globally optimal phrase alignment under 0(eij, fkl) derived from the Moses pipeline (Koehn et al., 2007).5 Table 1 shows that finding the optimal phrase alignment is accurate and efficient.6 Hence, this simple search technique effectively addresses the intractability challenges inherent in evaluating new phrase alignment ideas. The objective function is log 0(a) for a implied by {ai,j,k,l = 1}. Constraint equation 1 ensures that the English phrases form a partition of e – each word in e appears in exactly one phrase – as does equation 2 for f. Constraint equation 3 ensures that each phrase in the chosen partition of e appears in exactly one link, and that phrases not in the partition are not aligned (and likewise constraint 4 for f).