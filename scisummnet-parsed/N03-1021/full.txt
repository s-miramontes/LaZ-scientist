. translational equivalence between their components. Every link generated by a D-MTG has D components. Some (but not all) components of a link may be empty. An empty component indicates that an expression vanishes in translation. To express empty components, we add a special terminal E to T and a special nonterminal E to N. In MTG applications, the different components of a link will typically come from largely disjoint subsets of T or N, representing vocabularies or sets of grammatical categories from different languages. Each MTG also has a set of production rules (or just &quot;productions&quot; for short), which fall into one of two categories.' YIELD productions have the form where M is a non-empty vector of nonterminal links, P is a non-empty vector of D permutations, and N (&quot;join&quot;) is a rendering function, explained below.2 The rank of an MTG production is the number of nonterminal links on its RHS. The rank of an MTG is the maximum rank of its production rules. MTG(R) is the class of MTGs of rank R. Each row of P and M corresponds to a different component of multitext. Each permutation is written as a row in P, and each link is written as a column in M, as in Equation 3 below. If Xd is empty, then the dth component of every link in M must be empty too. If Xd is not empty, then at least one of the links in M must have a non-empty dth component. The position of a non-empty terminal or nonterminal relative to other non-empty elements of its component is its role. If there are m non-empty nonterminals in component (row) d of M then Pd is a permutation of roles from 1 to Tn. Pd is empty if and only if Xd is empty. The D-MTG derivation process begins with the start link $, which is a vector of D copies of the special start symbol $ E N. The derivation continues with nondeterministic application of production rules. The semantics of = are the usual semantics of rewriting systems, i.e., that the expression on the LHS can be rewritten as the expression on the RHS. Following convention, we let be the reflexive and transitive closure of When no more productions can be applied, i.e., when all nonterminals have been rewritten into terminals, the rendering functions are evaluated in inside-out order. The N function rearranges the nonempty terminals in each row of a link vector according to that row's permutation. For example, [1,2,3] (c ab c abc N [1,3,2,4] wyxcz =wxyz [3,2,1] t Env c vut By reordering the terminals independently in each component, the join operator hides information about which terminals were derived from the same link. Thus, the translational equivalence represented by links is not observable in MTG yields, just as it is not observable in raw multitext. To avoid spurious ambiguity, we stipulate a normal form for components of P: In each permutation, the first appearance of role x must precede the first appearance of role y for all x < y, except where the arrangement is incompatible with a preceding permutation in P. We could, for example, obtain the same result above if we put EZE first, put ewt last, and switch their roles in the 2nd and 3rd permutations. However, the normal form requires the 2nd permutation to be [1, 3, 2, 4], not [4, 3, 2, 1], so EZE must be listed last. Let Q be an MTG derivation where no more production rules can be applied. Let Render(Q) be the result of evaluating all the N's in Q. The (formal) language L(G) of an MTG G is the set of multitexts that can be generated by applying z to the start link of G and then evaluating all the joins. I.e., L(G) = {Render(Q) : $ z Q}. Due to the importance of lexical information in disambiguating syntactic structure, we shall pay special attention to lexicalized MTGs (LMTGs) of the bilexical variety (L2MTGs). A bilexical MTG has a set A of &quot;delexicalized&quot; nonterminal labels. Intuitively, A corresponds to the nonterminal set of an ordinary CFG. Then, every nonterminal in N has the form L[t] for some terminal t E T and some label L E A.3 The terminal t is the lexical head of its constituent, or just the head. One link on the RHS of each L2MTG production serves as the heir of the link on the LHS. Each component of the heir link inherits the lexical head of its parent nonterminal. An example of a 2-L2MTG derivation is in Figure 1. Some subclasses and superclasses of MTG have been studied before. The non-lexicalized class 2-MTG(2) is equivalent to ITG (Wu, 1997). Alshawi et al. (2000)'s &quot;collections of finite-state head transducers&quot; can be viewed as a subclass of 2-LMTG where, among other restrictions, A contains only one (dummy) nonterminal label. &quot;Syntax-directed translations of order k&quot; (Aho & Ullman, 1969) are equivalent to k-MTG(2). On the other hand, MTG is a subclass of Multiple CFG (Seki et al., 1991) where the functions that render the RHS of production rules may not mix symbols from different components.
3 Synchronous Parsers. Inference of synchronous structures requires a synchronous parser. A synchronous parser is an algorithm that can infer the syntactic structure of each component text in a multitext and simultaneously infer the correspondence relation between these structures.4 To facilitate complexity analysis (below), we specify our parsers using declarative inference rules.' &quot;X :- Y, Z&quot; means that X can be inferred from Y and Z. V means the same thing. An item that appears in an inference rule stands for the proposition that the item is in the parse chart. A production rule that appears in an inference rule stands for the proposition that the production is in the grammar. Such specifications are nondeterministic: they do not indicate the order in which a parser should attempt inferences. A deterministic parsing strategy can always be chosen later, to suit the application. Any reasonable parsing strategy will have the same asymptotic complexity (McAllester, 2002). For expository purposes, we begin with Parser R2D2A, which is a naive CKY-style chart parser for 2-L2MTG(2).6 The chart of Parser R2D2A is initialized with &quot;seed&quot; items, illustrated in Figure 2. A one-dimensional seed is put in the chart for every word in every component of the input. After initialization, the parser can translational equivalence between seeds components by firing Y inference rules: Y inference rules infer YIELD production rules. Each two-dimensional instantiation expresses the translational equivalence of two word tokens, h1 and h2, at positions i1 and i2 in their respective components. One-dimensional Y inferences assert that a word vanishes in translation. E.g. : Parser R2D2A spends most of its time composing pairs of non-seed items into larger items.7 A bottom-up one-dimensional parser composes onedimensional items until it infers an item that covers the input text. A bottom-up synchronous parser composes multi-dimensional items until it infers an item that covers the multitext space spanned by the input multitext. The items composed by naive synchronous parsers are called hyperedges, or hedges for short. The 2D hedges composed by Parser R2D2A are shown in Figure 2. The particular hedge in the figure represents a constituent between word boundaries i1 ji of the first compoAs we shall see in Section 5, however, bad binarization can worsen recognition complexity. The Binarization Rules apply deterministically,' but there are multiple ways to decompose the RHS of a nonbinary DEPEND production into nested joins.11 Some decompositions may give rise to more discontinuities than others. Let the cardinality of an RTV be the total number of partitions in all its components, and let the cardinality of a decomposition be the maximum cardinality of the RTVs that it contains. A minimizing decomposition for a given production is one of those with lowest cardinality. Then, the cardinality of a production is the cardinality of its minimizing decomposition. The cardinality of a production is bounded by its rank, as Table 1 shows for the 2D case. Finally, the cardinality C(G) of an MTG G is the maximum of the cardinalities of its productions.
5 Inference of Discontinuous Constituents. Parser A is a parser for arbitrary MTGs. It initializes its chart and fires Y inferences just like Parser R2A. It then composes pairs of items into larger items using inference rule A.0 (see below). Just like items in ordinary parsers, Parser A items need to know their positions in the input multitext, but not their internal structure. However, items with discontinuities need to remember all their boundaries, not just the outermost ones. Expanding on Johnson (1985), we define a discontinuous span (or dspan, for short) as a list of zero or more intervals In addition, we say that a d-span is in normal form if all the inequalities between ri and 4+1 are strict, i.e. there is a gap between each pair of consecutive intervals. Now, a hedge item X(a) in Parser A is a d-link X together with a vector of d-spans a in normal form. The cardinality of an item is the total number of intervals in its d-span vector. Binarized MTG productions can be inferred under generalizations of the ID and LP constraints described in Section 3. We use two helper functions to express these constraints. + is the concatenation operator for d-spans: Given two d-spans, it outputs the union of their intervals in normal form.12 The 0 function computes the role template that describes the relative positions of the intervals in two d-spans. E.g., if v = (1, 3; 8, 9) and a = (7,8), then v + o- = (1, 3; 7, 9) and v 0 o- = [1], [2, 1]. Both operators apply componentwise to vectors of d-spans. With their help, we state the composition inference rule of Parser A: The space complexity of Parser A is a function of the maximum number of boundaries stored in its item signatures, and the number INI of nonterminals in the grammar. The maximum number of required boundaries is exactly twice the cardinality of the MTG, and each of the boundaries can range over 0(n) possible positions. Thus, the space complexity of Parser A for an MTG G is in 0(1Ni D n2C (G) ) If G is bilexical, then the number of possible nonterminals hides a factor of nD , raising the space complexity of Parser A to 0 (ID np +2C (G)) The time complexity of Parser A depends on how many boundaries are shared between antecedent items in A.0 rules. In the best case, all the boundaries are shared except the two outermost boundaries in each dimension, and the inferred item is contiguous. In the worst case, no boundaries are shared, and the inferred item stores all the boundaries of the antecedent items. In any case, if y and z are the cardinalities of the composed items, and x is the cardinality of the inferred item, then the number of free boundaries in an A.0 inference is x + y + z. Thus, in the worst case, the number of free boundaries involved in an A.0 inference is 3C(G). As before, each boundary can range over 0(n) possible values, where n is the length of the longest component of the input multitext. We still have 3 nonterminal labels per dimension per inference. Also, each inference now needs to compute an RTV at a cost 12The inputs of ± must have no overlapping intervals, or else the output is undefined. A.C: in 0 (C (G)). Thus, the time complexity of Parser A is in 0 (C (G) INI3Dn3c(G)). For a binarized L2MTG, which also needs to keep track of two lexical heads per dimension per inference, this complexity rises to Parser B is a generalization of Parser R2B for binarized L2MTGs of arbitrary rank. It decomposes inference rule A.0 into ID and LP subrules, using generalized hooks that carry an RTV. The decomposition can happen in one of two ways, depending on the heir's role (1 or 2) in the DLV. The rules in Section 3.2 are simple examples of B.ID1 and B.LP1. Parser B is faster than Parser A, but takes more space. The hooks of Parser B must keep track of one more nonterminal label per dimension than hedges. The size of an RTV is bounded by the cardinality of the grammar. Thus, the space complexity of Parser B is in 0 (C (G)12D np-F2C(G)N ) On the other hand, The B.ID rules involve only one d-span instead of two, reducing the number of free variables by 0 (C (G)) . The B.LP rules again involve only one lexical head instead of two, reducing the number of free variables by a factor of D. Since D < C(G), it turns out that the worst-case running time of Parser B is less than that of Parser A by a factor of nD under L2MTGs of any rank and dimensionality.
6 Conclusion. We have proposed Multitext Grammars (MTGs) as a convenient and relatively expressive foundation for building practical models of translational equivalence. To encourage their use for this purpose, we have explored algorithms for parsing bilexical MTGs of arbitrary rank and dimensionality. Our exploration highlighted some little-known properties of synchronous parsing: (1) some optimizations of monolingual parsers generalize to the synchronous case, but others do not; (2) discontinuous constituents are essential for parsing bitexts even in similar Western languages; (3) different binarization schemes lead to different time and space complexity. There are many aspects of translational equivalence that MTG cannot express, such as some of those described by Dorr (1994). In future work, we hope to extend the formalism to cover some of the aspects that would not raise the computational complexity of its recognition, such as discontinuous and/or phrasal terminals. Concurrently, we shall explore the empirical properties of MTG, by inducing stochastic MTGs from real multitexts.
Acknowledgments. Thanks to Jason Eisner, Sanjeev Khudanpur, Owen Rambow, Giorgio Satta, and members of NYU's Proteus Project for helpful discussions. The idea of treating binarization as an optimization problem is due to Wei Wang. Dan Klein proposed the term &quot;hook.&quot; This research was supported by the DARPA TIDES program, by an NSF CAREER award, and by a gift from Sun Microsystems.