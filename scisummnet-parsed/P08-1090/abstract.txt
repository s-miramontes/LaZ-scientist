used in the 1970-80s as knowledge backbones that enabled inference and other NLP tasks requiring deep semantic knowledge. We propose unsupervised of similar schemata called chains raw newswire text. A narrative event chain is a partially ordered set of events related by a common protagonist. We describe a three step process to learning narrative event chains. The first uses unsupervised distributional methods to learn narrative relations between events sharing coreferring arguments. The second applies a temporal classifier to partially order the connected events. Finally, the third prunes and clusters self-contained chains from the space of events. introduce two evaluations: the evaluate event relatedness, and an orcoherence to evaluate narrative order. show a over baseline narrative prediction and temporal coherence. tate learning, and thus this paper addresses the three of chain induction: event ordering of events selection (pruning the event space into discrete sets). Learning these prototypical schematic sequences of events is important for rich understanding of text. Scripts were central to natural language understanding research in the 1970s and 1980s for proposed tasks such as summarization, coreference resolution and question answering. For example, Schank and Abelson (1977) proposed that understanding text about restaurants required knowledge about the Restaurant Script, including the participants (Customer, Waiter, Cook, Tables, etc. ), the events constituting the script (entering, sitting down, asking for menus, etc. ), and the various preconditions, ordering, and results of each of the constituent actions. Consider these two distinct narrative chains.