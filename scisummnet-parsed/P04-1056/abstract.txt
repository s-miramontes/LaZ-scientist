Most information extraction (IE) systems treat separate potential extractions as independent. However, in many cases, considering influences potential extractions could improve overall accuracy. Statistical methods on models, such as random fields have been shown to be an effective approach to learning accurate IE systems. We present a new IE method that employs Relational Markov Networks (a generalization of CRFs), which can represent arbitrary dependencies between extractions. This allows for &quot;collective information extraction&quot; that exploits the mutual influence between possible extractions. Experiments on learning to extract protein names from biomedical text demonstrate the advantages of this approach.