Hong Kong's stabilize boom is us life styles's pillar. Our prosperity and stability underpin our way of life. 44NMINVitta (Ben gang de jing ji qian jing yu zhang gu6, te bie shi guang dong sheng de jing ji qian jing xi xi xiang guan.) Hong Kong's economic foreground with China, particular Guangdong province's economic foreground vitally interrelated. Our economic future is inextricably bound up with China, and with Guangdong Province in particular. firdtittifirg.g. (WO win quin zhi chi ta de yi jian.) I absolutely uphold his views. I fully support his views. Mt (Zhe xie an pai ke jia qiing wo men ri hOu wei chi jin r6ng wen ding de neng 11.) These arrangements can enforce us future kept financial stabilization's competency. These arrangements will enhance our ability to maintain monetary stability in the years to come. tWt, ftRAMT.A1t: ZOM, ftrig*IliTtAtIttM3R/OIAMPfiEfissi R. wa zai ke yl ken ding de shuO, wO men jiang hul ti gong wei di dao ge xiang zhii yao mu biao suO xil de jing fei.) However, I now can certainty's say, will provide for us attain various dominant goal necessary's current expenditure. The consultation process is continuing but I can confirm now that the necessary funds will be made available to meet the key targets. Figure 4: Example translation outputs. translation accuracy was performed on a random sample drawn from Chinese sentences of fewer than 20 words from the parallel corpus, the results of which are shown in Figure 3. We have judged only whether the correct meaning (as determined by the corresponding English sentence in the parallel corpus) is conveyed by the translation, paying particular attention to word order, but otherwise ignoring morphological and function word choices. For comparison, the accuracies from the A*-based systems are also shown. There is no significant difference in the accuracy. Some examples of the output are shown in Figure 4. On the other hand, the new algorithm has indeed proven to be much faster. At present we are unable to use direct measurement to compare the speed of the systems meaningfully, because of vast implementational differences between the systems. However, the order-of-magnitude improvements are immediately apparent. In the earlier system, translation of single sentences required on the order of hours (Sun Sparc 10 workstations). In contrast the new algorithm generally takes less than one minute—usually substantially less—with no special optimization of the code. 6 Conclusion We have introduced a new algorithm for the runtime optimization step in statistical machine translation systems, whose polynomial-time complexity addresses one of the primary obstacles to practicality facing statistical MT. The underlying model for the algorithm is a combination of the stochastic BTG and bigram models. The improvement in speed does not appear to impair accuracy significantly. We have implemented a version that accepts ITGs rather than BTGs, and plan to experiment with more heavily structured models. However, it is important to note that the search complexity rises exponentially rather than polynomially with the size of the grammar, just as for context-free parsing (Barton, Berwick, and Ristad, 1987). This is not relevant to the BTG-based model we have described since its grammar size is fixed; in fact the BTG's minimal grammar size has been an important advantage over more linguistically-motivated ITG-based models. 157 We have also implemented a generalized version that accepts arbitrary grammars not restricted to normal form, with two motivations. The pragmatic benefit is that structured grammars become easier to write, and more concise. The expressiveness benefit is that a wider family of probability distributions can be written. As stated earlier, the normal form theorem guarantees that the same set of shapes will be explored by our search algorithm, regardless of whether a binary-branching BTG or an arbitrary BTG is used. But it may sometimes be useful to place probabilities on n-ary productions that vary with n in a way that cannot be expressed by composing binary productions; for example one might wish to encourage longer straight productions. The generalized version permits such strategies. Currently we are evaluating robustness extensions of the algorithm that permit words suggested by the language model to be inserted in the output sentence, which the original A* algorithms permitted. Acknowledgements Thanks to an anonymous referee for valuable comments, and to the SILC group members: Xuanyin Xia, Eva Wai-Man Fong, Cindy Ng, Hong-sing Wong, and Daniel Ka-Leung Chan. Many thanks also to Kathleen McKeown and her group for discussion, support, and assistance.