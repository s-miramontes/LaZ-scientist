. process of intra-family translation was handled by weighted string distance models of cognate similarity with a probabilistic representation of common intrafamily orthographic transformations. These models were iteratively reestimated using an ExpectationMaximization algorithm (Ristad and Yanilos 1997). When intra-family orthographic shifts are clear and systematic, such models can be quite effective on their own. In practice, the technique described suffers from the problem of faux amis â€” false cognates. For example, Serbian-Czech faux amis such as prazan-prizen and prazan-pazen can outrank the correct but orthographically less similar prazanprazdny, causing the English bridge pathways to the correct English translations blank and empty to be scored below the incorrect translation paths to favor, grace and patronage. This paper addresses the above-described model deficiency by proposing, developing and evaluating the use of 7 additional similarity models which successfully capture a set of complementary distributional behaviors. An algorithm combining them with weighted string distance significantly outperforms the previous bridge language approach on both English-Serbian and English-Gujarati test sets.
2 Resources. Our goal was to learn translation lexicons using resources that are available on the internet at no monetary cost. No seed dictionary is required between English and the language of interest; a sizeable dictionary between the bridge language and English is necessary. Our work with Serbian involved the use of a Czech-English dictionary initially containing roughly 171K Czech-English pairs, including 54K unique Czech word types and 43K unique English types. The Hindi-English dictionary contained around 74K pairs. The Serbian/Gujarati vocabularies we used were built by extracting all word types from the respective corpora, then filtering out lowfrequency words (since our similarity models require reliable corpus statistics) and very short words' (use of string distance to propose cognate candidates for very short words was seen to be unreliable in preliminary experiments). The corpora used here are composed of news data, the majority of which was downloaded from the internet. The English corpus contains 192M tokens; Serbian, 12M; Gujarati, 2M. English was lemmatized using a high-quality lemmatization utility; the Serbian, using minimally supervised morphological analysis as described in Yarowsky and Wicentowski (2000). Gujarati was not lemmatized. Where possible, date labels were extracted for news stories. This resulted in 1690 separate labeled days of news for Serbian and 233 for Gujarati. For each language task, English news data was marked as originating either locally or non'Words with length < 5 characters were excluded. locally with respect to areas where the language is spoken, in order to facilitate computation of datedistributional similarities across both strongly related, same-region news sources (date-local) and a general, worldwide aggregate news corpus (date-all).