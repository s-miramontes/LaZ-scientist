1 Introduction. Combinatory Categorial Grammar (Steedman, 1990), like other &quot;flexible&quot; categorial grammars, suffers from spurious ambiguity (Wittenburg, 1986). The non-standard constituents that are so crucial to CCG's analyses in (1), and in its account of intonational focus (Prevost & Steedman, 1994), remain available even in simpler sentences. This renders (2) syntactically ambiguous. The practical problem of &quot;extra&quot; parses in (2) becomes exponentially worse for longer strings, which can have up to a Catalan number of parses. An exhaustive parser serves up 252 CCG parses of (3), which must be sifted through, at considerable cost, in order to identify the two distinct meanings for further processing.' This paper presents a simple and flexible CCG parsing technique that prevents any such explosion of redundant CCG derivations. In particular, it is proved in §4.2 that the method constructs exactly one syntactic structure per semantic reading—e.g., just two parses for (3). All other parses are suppressed by simple normal-form constraints that are enforced throughout the parsing process. This approach works because CCG's spurious ambiguities arise (as is shown) in only a small set of circumstances. Although similar work has been attempted in the past, with varying degrees of success (Karttunen, 1986; Wittenburg, 1986; Pareschi & Steedman, 1987; Bouma, 1989; Hepple & Morrill, 1989; Ki5nig, 1989; Vijay-Shanker & Weir, 1990; Hepple, 1990; Moortgat, 1990; Hendriks, 1993; Niv, 1994), this appears to be the first full normal-form result for a categorial formalism having more than contextfree power.
2 Definitions and Related Work. CCG may be regarded as a generalization of contextfree grammar (CFG)—one where a grammar has infinitely many nonterminals and phrase-structure rules. In addition to the familiar atomic nonterminal categories (typically S for sentences, N for nouns, NP for noun phrases, etc. ), CCG allows in- signs different types to &quot;John likes&quot; and &quot;Mary prefinitely many slashed categories. If x and y are tends to like,&quot; thus losing the ability to conjoin such categories, then x/y (respectively x\y) is the cat- constituents or subcategorize for them as a class. egory of an incomplete x that is missing a y at its (Pareschi & Steedman, 1987) do tackle the CCG right (respectively left). Thus verb phrases are an- case, but (Hepple, 1987) shows their algorithm to alyzed as subjectless sentences S \NP, while &quot;John be incomplete. likes&quot; is an objectless sentence or S/NP. A complex 3 Overview of the Parsing Strategy category like ( (S \NP) \ (S \NP))/N may be written as As is well known, general CFG parsing methods S \NP \ (S \NP)/N, under a convention that slashes are can be applied directly to CCG. Any sort of chart left-associative. parser or non-deterministic shift-reduce parser will The results herein apply to the TAG-equivalent do. Such a parser repeatedly decides whether two CCG formalization given in (Joshi et al., 1991).2 adjacent constituents, such as S/NP and NP/N, should In this variety of CCG, every (non-lexical) phrase- be combined into a larger constituent such as S/N. structure rule is an instance of one of the following The role of the grammar is to state which combibinary-rule templates (where n 0): nations are allowed. The key to efficiency, we will (4) Forward generalized composition >Bn: see, is for the parser to be less permissive than the xly Y Inzn • • • 12z2 lizi Inn • • • I2z2 lizi grammar—for it to say &quot;no, redundant&quot; in some Backward generalized composition <Bn: cases where the grammar says &quot;yes, grammatical.&quot; Y Inzn • • I2z2 lizi \Y x Inzn • • • I I (5) shows the constituents that untrammeled ,2z2 ,izi CCG will find in the course of parsing &quot;John likes Instances with n = 0 are called application rules, and Mary.&quot; The spurious ambiguity problem is not that instances with n > 1 are called composition rules. In the grammar allows (5c), but that the grammar ala given rule, x,y,z1...zn would be instantiated as lows both (5f) and (5g)—distinct parses of the same categories like NP, S/NP, or S \NP \ (S\NP)/N. Each of string, with the same meaning. 11 through ln would be instantiated as either / or \ (5) a. [John]si(s\Np) A fixed CCG grammar need not include every b. [likes](swp)/Np phrase-structure rule matching these templates. In- c. [John likes]siNp deed, (Joshi et al., 1991) place certain restrictions d. [Mary]Np on the rule set of a CCG grammar, including a re- e. [likes Mary]s \Np quirement that the rule degree n is bounded over the f. [[John likes] Mary]s to be disallowed set. The results of the present paper apply to such g. [John [likes Mary]]s restricted grammars and also more generally, to any The proposal is to construct all constituents CCG-style grammar with a decidable rule set. shown in (5) except for (5f). If we slightly conEven as restricted by (Joshi et al., 1991), CCGs strain the use of the grammar rules, the parser will have the &quot;mildly context-sensitive&quot; expressive power still produce (5c) and (5d)—constituents that are of Tree Adjoining Grammars (TAGs). Most work indispensable in contexts like (1)—while refusing to on spurious ambiguity has focused on categorial for- combine those constituents into (51). The relevant malisms with substantially less power. (Hepple, rule S/NP NP S will actually be blocked when it 1990) and (Hendriks, 1993), the most rigorous pieces attempts to construct (5f). Although rule-blocking of work, each establish a normal form for the syn- may eliminate an analysis of the sentence, as it does tactic calculus of (Lambek, 1958), which is weakly here, a semantically equivalent analysis such as (5g) context-free. (Konig, 1989; Moortgat, 1990) have will always be derivable along some other route. also studied the Lambek calculus case. (Hepple In general, our goal is to discover exactly one analMorrill, 1989), who introduced the idea of normal- ysis for each <substring, meaning> pair. By pracform parsing, consider only a small CCG frag- ticing &quot;birth control&quot; for each bottom-up generation ment that lacks backward or order-changing com- of constituents in this way, we avoid a population position; (Niv, 1994) extends this result but does explosion of parsing options. &quot;John likes Mary&quot; has not show completeness. (Wittenburg, 1987) assumes only one reading semantically, so just one of its anala CCG fragment lacking order-changing or higher- yses (5f)–(5g) is discovered while parsing (6). Only order composition; furthermore, his revision of the that analysis, and not the other, is allowed to concombinators creates new, conjoinable constituents tinue on and be built into the final parse of (6). that conventional CCG rejects. (Bouma, 1989) pro- (6) that galoot in the corner that thinks [John poses to replace composition with a new combina- likes MarAs tor, but the resulting product-grammar scheme as- For a chart parser, where each chart cell stores the analyses of some substring, this strategy says that 2This formalization sweeps any type-raising into the 80 lexicon, as has been proposed on linguistic grounds (Dowty, 1988; Steedman, 1991, and others). It also treats conjunction lexically, by giving &quot;and&quot; the generalized category x\x/x and barring it from composition. all analyses in a cell are to be semantically distinct. (Karttunen, 1986) suggests enforcing that property directly—by comparing each new analysis semantically with existing analyses in the cell, and refusing to add it if redundant—but (Hepple & Morrill, 1989) observe briefly that this is inefficient for large charts.3 The following sections show how to obtain effectively the same result without doing any semantic interpretation or comparison at all.
4 A Normal Form for &quot;Pure&quot; CCG. It is convenient to begin with a special case. Suppose the CCG grammar includes not some but all instances of the binary rule templates in (4). (As always, a separate lexicon specifies the possible categories of each word.) If we group a sentence's parses into semantic equivalence classes, it always turns out that exactly one parse in each class satisfies the following simple declarative constraints: The notation here is from (4). More colloquially, (7) says that the output of rightward (leftward) composition may not compose or apply over anything to is right (left). A parse tree or subtree that satisfies (7) is said to be in normal form (NF). As an example, consider the effect of these restrictions on the simple sentence &quot;John likes Mary.&quot; Ignoring the tags —OT, —FC, and —BC for the moment, (8a) is a normal-form parse. Its competitor (813) is not, nor is any larger tree containing (8b). But non3How inefficient? (i) has exponentially many semantically distinct parses: n = 10 yields 82,756,612 parses in (2°) = 48,620 equivalence classes. Karttunen's io method must therefore add 48,620 representative parses to the appropriate chart cell, first comparing each one against all the previously added parses—of which there are 48,620/2 on average—to ensure it is not semantically redundant. (Additional comparisons are needed to reject parses other than the lucky 48,620.) Adding a parse can therefore take exponential time. Structure sharing does not appear to help: parses that are grouped in a parse forest have only their syntactic category in common, not their meaning. Karttunen's approach must tease such parses apart and compare their various meanings individually against each new candidate. By contrast, the method proposed below is purely syntactic—just like any &quot;ordinary&quot; parser—so it never needs to unpack a subforest, and can run in polynomial time. standard constituents are allowed when necessary: (8c) is in normal form (cf. (1)). It is not hard to see that (7a) eliminates all but right-branching parses of &quot;forward chains&quot; like A/B B/C C or A/B/C C/D D/E/F/G G/H, and that (7b) eliminates all but left-branching parses of &quot;backward chains.&quot; (Thus every functor will get its arguments, if possible, before it becomes an argument itself.) But it is hardly obvious that (7) eliminates all of CCG 's spurious ambiguity. One might worry about unexpected interactions involving crossing composition rules like A/B B \C –4- A \ C. Significantly, it turns out that (7) really does suffice; the proof is in §4.2. It is trivial to modify any sort of CCG parser to find only the normal-form parses. No semantics is necessary; simply block any rule use that would violate (7). In general, detecting violations will not hurt performance by more than a constant factor. Indeed, one might implement (7) by modifying CCG's phrase-structure grammar. Each ordinary CCG category is split into three categories that bear the respective tags from (9). The 24 templates schematized in (10) replace the two templates of (4). Any CFG-style method can still parse the resulting spuriosity-free grammar, with tagged parses as in (8). In particular, the polynomial-time, polynomialspace CCG chart parser of (Vijay-Shanker & Weir, 1993) can be trivially adapted to respect the constraints by tagging chart entries.
A/C/D D/F A/B B/C/D D/E E/F. It is interesting to note a rough resemblance between the tagged version of CCG in (10) and the tagged Lambek calculus L*, which (Hendriks, 1993) developed to eliminate spurious ambiguity from the Lambek calculus L. Although differences between CCG and L mean that the details are quite different, each system works by marking the output of certain rules, to prevent such output from serving as input to certain other rules. We wish to establish that each semantic equivalence class contains exactly one NF parse. But what does &quot;semantically equivalent&quot; mean? Let us adopt a standard model-theoretic view. For each leaf (i.e., lexeme) of a given syntax tree, the lexicon specifies a lexical interpretation from the model. CCG then provides a derived interpretation in the model for the complete tree. The standard CCG theory builds the semantics compositionally, guided by the syntax, according to (11). We may therefore regard a syntax tree as a static &quot;recipe&quot; for combining word meanings into a phrase meaning. One might choose to say that two parses are semantically equivalent if they derive the same phrase meaning. However, such a definition would make spurious ambiguity sensitive to the fine-grained semantics of the lexicon. Are the two analyses of VP/VP VP VP \VP semantically equivalent? If the lexemes involved are &quot;softly knock twice,&quot; then yes, as softly(twice(knock)) and twice(softly(knock)) arguably denote a common function in the semantic model. Yet for &quot;intentionally knock twice&quot; this is not the case: these adverbs do not commute, and the semantics are distinct. It would be difficult to make such subtle distinctions rapidly. Let us instead use a narrower, &quot;intensional&quot; definition of spurious ambiguity. The trees in (12a—b) will be considered equivalent because they specify the same &quot;recipe,&quot; shown in (12c). No matter what lexical interpretations f,g,h,k are fed into the leaves A/B, B/C/D, D/E, E/F, both the trees end up with the same derived interpretation, namely a model element that can be determined from f,g,h,k by calculating AxAy.f(g(h(k(x)))(y)). By contrast, the two readings of &quot;softly knock twice&quot; are considered to be distinct, since the parses -+ specify different recipes. That is, given a suitably Q fit NF T NF(a) free choice of meanings for the words, the two parses 131 /32 132 7 can be made to pick out two different VP-type func- This construction resembles a well-known normaltions in the model. The parser is therefore conser- form reduction procedure that (Hepple 8.6 Morrill, vative and keeps both parses.' 1989) propose (without proving completeness) for a 4.2 Normal-form parsing is safe Sz complete small fragment of CCG. The motivation for producing only NF parses (as The proof of theorem 2 (completeness) is longer defined by (7)) lies in the following existence and and more subtle. First it shows, by a simple inducuniqueness theorems for CCG. tion, that since a and a' disagree they must disagree Theorem 1 Assuming &quot;pure CCG,&quot; where all pos- in at least one of these ways: sible rules are in the grammar, any parse tree a is se- (a) There are trees /3, -y and rules R R' such that mantically equivalent to some NF parse tree NF(a). <R, #,7> is a subtree of a and <R', 0,7> is a (This says the NF parser is safe for pure CCG: we subtree of a'. (For example, S/S S \ S may form will not lose any readings by generating just normal a constituent by either <Blx or >Bix.) forms.) (b) There is a tree 7 that appears as a subtree of Theorem 2 Given distinct NF trees a 0 a' (on the both a and a', but combines to the left in one same sequence of leaves). Then a and a' are not case and to the right in the other. semantically equivalent. Either condition, the proof shows, leads to different (This says that the NF parser is complete: generat- &quot;immediate scope&quot; relations in the full trees a and a' ing only normal forms eliminates all spurious ambi- (in the sense in which f takes immediate scope over guity.) g in f(g(x)) but not in f(h(g(x))) or g(f(x))). ConDetailed proofs of these theorems are available on dition (a) is straightforward. Condition (b) splits the al-T-1g archive, but can only be sketched here. into a case where -y serves as a secondary argument Theorem 1 is proved by a constructive induction on inside both a and a', and a case where it is a primary the order of a, given below and illustrated in (13): argument in a or a'. The latter case requires consid• For a a leaf, put NF(a) = a. eration of 7's ancestors; the NF properties crucially • (<R, 0,7> denotes the parse tree formed by com- rule out counterexamples here. bining subtrees 13, 7 via rule R.) The notion of scope is relevant because semantic If a = <R,/3,7>, then take NF(a) = interpretations for CCG constituents can be written <R, NF(#),NF(-y)>, which exists by inductive as restricted lambda terms, in such a way that conhypothesis, unless this is not an NF tree. In stituents having distinct terms must have different the latter case, WLOG, R is a forward rule and interpretations in the model (for suitable interpretaNF(#) = <Q, 13i, /32> for some forward com- tions of the words, as in §4.1). Theorem 2 is proved position rule Q. Pure CCG turns out to pro- by showing that the terms for a and a' differ somevide forward rules S and T such that a' = where, so correspond to different semantic recipes. <S, , NF(<T, , 7>)> is a constituent and Similar theorems for the Lambek calculus were is semantically equivalent to a. Moreover, since previously shown by (Hepple, 1990; Hendriks, 1993). 131 serves as the primary subtree of the NF tree The present proofs for CCG establish a result that NF(#), fi1. cannot be the output of forward com- has long been suspected: the spurious ambiguity position, and is NF besides. Therefore a' is NF: problem is not actually very widespread in CCG. take NF(a) = a'. Theorem 2 says all cases of spurious ambiguity Theorem 2 remains true (< 1 NF per reading). that their NFs have been previously computed. Whether theorem 1 (> 1 NF per reading) remains Figure (1) gives an efficient CKY-style algorithm true depends on what set of rules is removed. For based on this insight. (Parsing strategies besides most linguistically reasonable choices, the proof of CKY would also work, in particular (Vijay-Shanker theorem 1 will go through,' so that the normal-form Si Weir, 1993)) The management of cached NFs in parser of §4 remains safe. But imagine removing steps 9, 12, and especially 16 ensures that duplicate only the rule B/C C B: this leaves the string A/B NFs never enter the oldNFs array: thus any alterB/C C with a left-branching parse that has no (legal) native copy of a.nf has the same array coordinates NF equivalent. used for a.nf itself, because it was built from identiIn the sort of restricted grammar where theorem 1 cal subtrees. does not obtain, can we still find one (possibly non- The function PreferableTo(c, r) (step 15) proNF) parse per equivalence class? Yes: a different vides flexibility about which parse represents its kind of efficient parser can be built for this case. class. PreferableTo may be defined at whim to Since the new parser must be able to generate a choose the parse discovered first, the more leftnon-NF parse when no equivalent NF parse is avail- branching parse, or the parse with fewer nonable, its method of controlling spurious ambiguity standard constituents. Alternatively, PreferableTo cannot be to enforce the constraints (7). The old may call an intonation or discourse module to pick parser refused to build non-NF constituents; the new the parse that better reflects the topic-focus diviparser will refuse to build constituents that are se- sion of the sentence. (A variant algorithm ignores mantically equivalent to already-built constituents. PreferableTo and constructs one parse forest per This idea originates with (Karttunen, 1986). reading. Each forest can later be unpacked into inHowever, we can take advantage of the core result dividual equivalent parse trees, if desired.) of this paper, theorems 1 and 2, to do Karttunen's (Vijay-Shanker Sz Weir, 1990) also give a method redundancy check in 0(1) time—no worse than the for removing &quot;one well-known source&quot; of spurious normal-form parser's check for —FC and –BC tags. ambiguity from restricted CCGs; §4.2 above shows (Karttunen's version takes worst-case exponential that this is in fact the only source. However, their time for each redundancy check: see footnote §3.) method relies on the grammaticality of certain interThe insight is that theorems 1 and 2 estab- mediate forms, and so can fail if the CCG rules can lish a one-to-one map between semantic equivalence be arbitrarily restricted. In addition, their method classes and normal forms of the pure (unrestricted) is less efficient than the present one: it considers CCG: parses in pairs, not singly, and does not remove any (15) Two parses a, a' of the pure CCG are parse until the entire parse forest has been built. semantically equivalent if they have the 6 Extensions to the CCG Formalism same normal form: NF(a)= NF(a'). In addition to the Bn (&quot;generalized composition&quot;) The NF function is defined recursively by §4.2's rules given in §2, which give CCG power equivalent proof of theorem 1; semantic equivalence is also to TAG, rules based on the S (&quot;substitution&quot;) and defined independently of the grammar. So (15) is T (&quot;type-raising&quot;) combinators can be linguistically meaningful and true even if a, a' are produced by useful. S provides another rule template, used in a restricted CCG. The tree NF(a) may not be a the analysis of parasitic gaps (Steedman, 1987; Szlegal parse under the restricted grammar. How- abolcsi, 1989): ever, it is still a perfectly good data structure that (16) a. >s: x/y liz y liz --+ x liz can be maintained outside the parse chart, to serve 11 f g Az. f(z)(g(z)) b. <S: y liz x\Y liz –+ x liz Although S interacts with Bn to produce another source of spurious ambiguity, illustrated in (17), the additional ambiguity is not hard to remove. It can be shown that when the restriction (18) is used together with (7), the system again finds exactly one 84 'For the proof to work, the rules S and T must be available in the restricted grammar, given that R and Q are. This is usually true: since (7) favors standard constituents and prefers application to composition, most grammars will not block the NF derivation while allowing a non-NF one. (On the other hand, the NF parse of A/B B/C C/D/E uses >B2 twice, while the non-NF parse gets by with >B2 and >B1.) Type-raising presents a greater problem. Various new spurious ambiguities arise if it is permitted freely in the grammar. In principle one could proceed without grammatical type-raising: (Dowty, 1988; Steedman, 1991) have argued on linguistic grounds that type-raising should be treated as a mere lexical redundancy property. That is, whenever the lexicon contains an entry of a certain category X, with semantics x, it also contains one with (say) category T/ (T \X) and interpretation Ap.p(x). As one might expect, this move only sweeps the problem under the rug. If type-raising is lexical, then the definitions of this paper do not recognize (19) as a spurious ambiguity, because the two parses are now, technically speaking, analyses of different sentences. Nor do they recognize the redundancy in (20), because—just as for the example &quot;softly knock twice&quot; in §4.1—it is contingent on a kind of lexical coincidence, namely that a type-raised subject commutes with a (generically) type-raised object. Such ambiguities are left to future work.
7 Conclusions. The main contribution of this work has been formal: to establish a normal form for parses of &quot;pure&quot; Cornbinatory Categorial Grammar. Given a sentence, every reading that is available to the grammar has exactly one normal-form parse, no matter how many parses it has in toto. A result worth remembering is that, although TAG-equivalent CCG allows free interaction among forward, backward, and crossed composition rules of any degree, two simple constraints serve to eliminate all spurious ambiguity. It turns out that all spurious ambiguity arises from associative &quot;chains&quot; such as A/B B/C C or A/B/C C/D D/E\F/G G/H. (Wit8 5 tenburg, 1987; Hepple & Morrill, 1989) anticipate this result, at least for some fragments of CCG, but leave the proof to future work. These normal-form results for pure CCG lead directly to useful parsers for real, restricted CCG grammars. Two parsing algorithms have been presented for practical use. One algorithm finds only normal forms; this simply and safely eliminates spurious ambiguity under most real CCG grammars. The other, more complex algorithm solves the spurious ambiguity problem for any CCG grammar, by using normal forms as an efficient tool for grouping semantically equivalent parses. Both algorithms are safe, complete, and efficient. In closing, it should be repeated that the results provided are for the TAG-equivalent Bn (generalized composition) formalism of (Joshi et al., 1991), optionally extended with the S (substitution) rules of (Szabolcsi, 1989). The technique eliminates all spurious ambiguities resulting from the interaction of these rules. Future work should continue by eliminating the spurious ambiguities that arise from grammatical or lexical type-raising.