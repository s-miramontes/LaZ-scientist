1 Introduction. Human translators and machine translation systems are often faced with the task of transliterating phrases like person names and locations. Transliteration is the process of replacing words in the source language with their approximate phonetic or spelling equivalents in the target language. Transliterating names between languages that use similar alphabets and sound systems is often very simple, since the phrase mostly remains the same. However, the transliteration becomes far more difficult when transliterating between languages with very different sound and writing systems. When transliterating a name from Arabic into English, there are two types of transliterations: transliteration of an Arab name into English. Typically, many variations of the transliterated name are acceptable. This is especially true when transliterating between two languages with many phonetic incompatibilities, such as Arabic and English. For example, the Arab name &quot;_.A ycisr&quot;1 can reasonably be transliterated in any of the following ways: Yasir, Yassir, Yaser, Yasser, etc. Transliterating names from Arabic into English in either direction is a difficult task, mainly due to the differences in their sound and writing systems. For instance, vowels in Arabic come in two varieties, long and short. Short vowels are rarely written in Arabic in newspaper text, which makes pronunciation highly ambiguous. Also, because of the differences in their sound inventory, there is no one-to-one correspondence between Arabic sounds and English sounds. For example, English P and B are both mapped into Arabic &quot;,_.) b&quot;; Arabic &quot;c and &quot;A h-&quot; into English H; and so on. In this paper, we describe Arabic-to-English name transliteration system using probabilistic finite state machines2 that address both the transliteration of Arab and foreign names into English.
2 Related Work. Kawtrakul et al. (1998) present a back transliteration system from Thai into English in the context of document retrieval. In their approach, loan words are first segmented into syllables using a combination of rules and statistical techniques. Then, syllables are mapped to phonemes based on some transcription rules. The phoneme sequence of the loan word is compared to the phonetic sequence of a set of English words found in a phonetic dictionary and the word with the most similar phonetic sequence is selected as the transliteration. The approach described by Kawtrakul et al. (1998) requires a phonetic dictionary of English in order to match phonetic sequences. Only those words with known phonetic sequences in the dictionary can be mapped by the transliteration system. Also, applying such technique to Arabic will most likely fail because without short vowels, the pronunciation is highly ambiguous, and so is its corresponding phonetic sequence. Arbabi et al. (1994) describe an algorithm for the forward-transliteration of Arab names into a number of Romance and Germanic languages including English, French, and Spanish. The transliteration process starts by vowelizing the given Arab name by inserting the appropriate short vowels which originally are not written but necessary for the correct pronunciation of the names. Then, the vowelized Arab name is converted into its phonetic Roman representation using a parser and table lookup. The phonetic representation is then used in a table lookup to produce the spelling in the desired language. The vowelization rules described by Arbabi et al. (1994) apply only to Arab names that conform to strict Arabic morphological rules. Any name that does not conform to the morphological rules is ignored and hence no transliteration will be attempted. This restriction limits the applicability of this approach since many person and organization names do not conform to morphological rules, especially loan words and foreign names. Stalls and Knight (1998) present an Arabic-toEnglish back-transliteration system based on the source-channel framework. The transliteration process is based on a generative model of how an English name is transliterated into Arabic. It consists of several steps, each defined as a probabilistic model represented as a finite state machine. First, an English word w is generated according to its unigram probabilities Pe). Then, the English word w is pronounced (i.e., converted to sound sequence c) with probability P (61w) which is collected directly from an English pronunciation dictionary. Finally, the English phoneme sequence is converted into Arabic writing with probability P (a lc), which we discuss in details in Section 4. The pronunciation model P(e I w) converts English letter sequences into English sound sequences. The model proposed by Stalls and Knight (1998) uses a pronunciation dictionary to do this conversion. Therefore, only words with known pronunciations in the dictionary can be transliterated. One way to overcome this limitation is to train a model that can map any given English letter sequence into its corresponding English sound sequence. This mapping is a complex task because of the mismatch between English spelling and English pronunciation. This difficulty, coupled with the difficulty of mapping Arabic letter sequences to English sound sequences, renders this choice unattractive. Instead we propose a spelling-based model that maps directly into Arabic letter sequences, which can be trained on an English/Arabic name list as we describe in Section 5. But before we present any further details, we describe our evaluation data next.
3 Evaluation Data. Our evaluation corpora consist of two data sets, a development test set and a blind one. The two sets consist of a list of person names extracted from Arabic newspaper articles. The development test set contains 854 names (377 unique names) and the blind test set contains 218 (85 unique names). The person names are then manually transliterated into English. The transliterations are then thoroughly reviewed and any obvious mistakes corrected.3 The corrected transliterations form the gold-standard we will compare our results with. We would like to investigate the suitability of the models proposed here for back- and forwardtransliteration. Therefore, each name in the list is classified in one of three categories ARABIC, for names of Arabic origin; ENGLISH, for names of English origin; and OTHER, for names of other origins including Chinese, Russian, Indian, etc. The names were classified by a bilingual speaker (a native speaker of Arabic). The classification is not always clear cut. In some cases, the first name of a person might be of one category and the last name of another (e.g.,&quot;jn....4.. j..c.&quot; Ali Rodriguez). In such cases, the category is chosen based on the identity of the person if it is known, otherwise the category of the last name is chosen. The distribution of person According to this model, the probability of transliterating Arabic word a into English word w is given by the following equation: The actual transliteration process is a graphsearch problem through millions of possible mappings to find the best path with English word sequence w that maximizes Pp(' Wia for a given Arabic word sequence a, as described by Knight and Graehl (1997).
5 Spelling-Based Model. One serious limitation of the phonetic-based model described above is that only English words with known pronunciations can be produced. For backtransliterating person names of English origin, this is not a big problem because many of such names are typically found in the dictionary. However, applying this technique to transliterate names of origins other than English is not going to work, because many such names are not likely to be in the dictionary despite the fact that the dictionary has more than 100,100 entries in it, as shown in Table 2. Moreover, if we want to apply this technique to transliterate a name into a language other than English, a large pronunciation dictionary is needed for that language, which is not easily obtainable. Also, human translators often transliterate words based on how they are spelled in the source language. For example, Graham is typically transliterated by humans into Arabic as &quot;r .Orciham&quot; and not as jrcim&quot; . Also, both &quot; hwjz&quot; and 13...4 hywzn occur in our corpus as possible transliterations for Hughes (both occurred as a transliteration for Karen Hughes). To back-transliterate such instances, one would need to consider spelling-based mappings not just sound mappings. To address these limitations, we propose a new spelling-based model that can be used alone or in conjunction with the phonetic-based model. The new model outperforms the phonetic-based model, even when evaluated on names found in the phonetic dictionary as we will discuss in more detail in Section 8. The spelling-based model we propose directly maps English letter sequences into Arabic letter sequences with probability P(alw), which is trained on an English/Arabic name list without the need for English pronunciations. Since no pronunciations are needed, this list is easily obtainable for many language pairs. We also extend the model P(w) to include a letter trigram model in addition to the word unigram model. This makes it possible to generate words that are not already defined in the word unigram model but obey English patterns. The word unigram model can be trained on any list of words. When trained on a list of person names, the transliterations will be most accurate for person names. For the experiments reported in this paper, the unigram model was trained on the list of names (without their pronunciations) from the CMU dictionary. The letter trigram is also trained on the same list. The transliteration score according to this model is given by: For a given Arabic name a, the actual transliteration process is carried out by searching for the English word sequence that maximizes Ps (w la ) In our spelling-based model, a sequence of one or more English letters is mapped to a sequence of zero Dictionary presented by the category of each name. OVERALL is a weighted average of the three categories. or more Arabic letters.' English letter sequences are typically longer than their Arabic equivalents for many reasons. First, because Arabic short vowels are not written and need to be &quot;guessed&quot; by the model. Second, English names often have silent letters that mostly are not reflected in the Arabic equivalent (e.g., Knight is transliterated as uclyt&quot; ). This phenomenon was also reflected in the learned model. Here is an example of some of the parameters learned during training: Here are some examples of the letter sequence alignments for pairs of Arabic name/top transliteration as provided by our system. Example I: Given the name &quot;r Luc sdam,&quot; its top transliteration was SADDAM, and the letter sequence alignment was: 6To reduce the parameters to be estimated and prevent data sparseness without loss of any practical modeling power, English letter sequences were restricted to a maximum of 3 letters, while Arabic ones were restricted to a maximum of 2 letters. Example III: Given the name &quot; )wbuhciymr,&quot; its top transliteration was OPPENHEIMER, and the letter sequence alignment was:
6 Combining The Phonetic-Based and Spelling-Based Models. The phonetic-based and spelling-based models can be linearly combined into a single transliteration model. The transliteration score for an English word w given an Arabic word a is a linear combination of the phonetic-based and the spelling-based transliteration scores as follows:7
7 Improving Transliterations. In this section we discuss two different techniques that were used to improve the transliteration accuracy. In the first technique, the given word to be transliterated is pre-processed to correct any typos and spelling errors. The spelling correction model described in Section 7.1 is also implemented using a finite state machine which can be easily added to the transliteration composition pipeline. In the second technique to improve transliterations, transliterations are post-processed to filter any unlikely transliterations as described in Section 7.2. Typos and misspellings are very common in Arabic newspapers, especially in on-line editions. Typical Tor the experiments reported in this paper, we used A = 0.5. with and without spelling correction. The results shown here are for the phonetic-based model. The Topl results considers whether the correct answer is the top candidate or not, while the Top20 results considers whether the correct answer is among the top-20 candidates. typos stem from replacing a letter with another that has a similar shape, especially when they are mapped to adjacent keys on the keyboard layout (e.g., &quot;t..&quot; and &quot;c'; &quot;cj,&quot; and &quot;3'; and so on). These letters have very different sounds and without being corrected, names with those typos will most likely be transliterated incorrectly. For example, the name €wuzcilys&quot; is a misspelled version of the name &quot;Ly4).;:c. jwuzcilys&quot; (Gonzalez). Spaces are reliably used in Arabic to separate words, with very few exceptions. Arabic employs a cursive writing system, so typically letters in the same word are connected to each other. Most letters can be connected from both sides, but some (such as &quot; , , &quot; J&quot;, and &quot; j' )' can be connected only from the right side. After any of these letters, a space might be incorrectly deleted (e.g., &quot;,:y3_,J.,ti...a:jit,&quot; instead of &quot;,:y3_,J.,ti...a) bytr mndlswn&quot;) or inserted (e.g., &quot;Alfl Ats b d allh&quot; instead of &quot;ABlats. €bdcillh&quot;). Additionally, there are common misspellings that can be found even in the most respected Arabic newspapers, e.g., interchanging one form of an alif (&quot;i&quot;, &quot;p', &quot;p', or &quot;p') with another, especially at the beginning of a word; or interchanging &quot;a&quot; and &quot;s&quot; at the end of a word; etc. These kinds of typos and misspellings are more common than we expected. For example, 5% of the names in our development test set were misspelled. Human translators seem to be able to recover from name misspellings when transliterating a name they are familiar with. Our human subject was able to transliterate the name &quot;,..).4 bwrys&quot; (Boris) correctly, even though it was misspelled as &quot;Lty, brwys.&quot; Therefore, we believe that we need to model misspellings explicitly rather than hope that they will not cause wrong transliterations. We model misspellings by using an additional finite-state machine at the end of the cascade of finite state machines. We would like to estimate the parameters in this model empirically. But since we do not have enough misspellings/correct spelling pairs to train this model, the weights were set manually. The use of this spelling correction model slightly improves our transliterations, as shown in Table 3. As we have described in Section 5, the P(w) model is a combination of a word unigram model and a letter trigram model. The latter is needed in order to be able to generate words that are not in the word unigram model. However, despite being trained on a long list of names, the letter trigram model occasionally produce unlikely candidates. Unlikely candidates can be eliminated by filtering out candidates with zero Web counts. The Web-based filtering is useful only for our spelling-based model since all candidates generated by the phonetic-based model are in the pronunciation dictionary and all have non-zero Web counts. A comparison of the transliteration accuracy with and without the Web-based filtering is shown in Table 4.
8 Evaluation and Experimental Results. In this section, we present a comparison of the accuracy of the phonetic-based model, the spelling-based model, and the linear combination in transliterating names from Arabic into English on the development and test sets. We also, present the transliteration accuracy of human translators on the same task. The results presented in Section 8.1 and Section 8.2 are based on the exact-matching criterion (i.e., a transliteration is considered correct only if it exactly matches the one in the gold-standard). We also show the accuracy based on human-subjective evaluation in Section 8.3. We wanted to know how well human translators do in this task. So, we asked a bilingual speaker (a native speaker of Arabic) to transliterate the names in both data sets given the context they appear within in the Arabic document. Then, the transliterations provided by the human subject are compared with those in the gold-standard. The accuracy of the transliterations provided by the human translator is shown in Table 5. Examples of the transliteration errors made by the human subject are shown in Table 6. We first show in Section 8.2.1 the overall accuracy of the phonetic-based model, the spelling-based model, and the linear combination of them. Then, in Section 8.2.2 we show how the presence of names in the pronunciation dictionary affects the transliterations obtained using our models. We also present some transliteration errors made by our algorithm in Section 8.2.3. Table 7 shows the transliteration accuracy of the spelling-based model, the phonetic-based model, and the linear combination on the development and blind test set. The spelling-based model was by far more accurate than the phonetic-based model in all three categories and on both data sets. Because it combines the transliterations of the two models, we expected the linear combination to be the most accurate. However, this was not the case. The linear combination was slightly worse than the spellingbased model when considering only the top candidate, and slightly better when considering the top20 candidates. We believe that the reason is that equal weights were given to the phonetic-based and spelling-based models in the combination. Weighting the spelling-based model higher will most likely give more accurate transliterations. 8.2.2 Phonetic-Based vs. Spelling Based on Names in the Dictionary As we have described in Section 4, the phoneticbased model uses a pronunciation dictionary to convert an English phoneme sequence to an English word sequence. Consequently, only words with known pronunciations (from the dictionary) can be generated using this model. Therefore, the spellingbased model generally has a higher transliteration accuracy. But, does the spelling-based model generate more accurate transliterations for words with known pronunciations? We expected the answer to this question to be no. But much to our surprise, the spelling-based model produced more accurate transliterations on all categories, as shown in Table 8. When top-20 transliterations were considered, the spelling-based model was slightly less accurate. As expected, the transliterations for names in the pronunciation dictionary are much more accurate than those that are not in it. This is because the word unigram model P(w) was trained on names in the dictionary. Table 9 shows some examples of the transliteration errors made by our transliteration algorithm. Some of the errors occurred were in fact not errors but rather acceptable alternative transliterations. However, many were true errors. The human-subjective evaluation described in Section 8.3 helps distinguish between these two cases. The evaluation results presented so far consider a transliteration correct only if it matches the goldstandard. In some cases where more than one possible transliteration is acceptable, this criterion is too rigid. To address such cases, we must ask a human subject to determine the correctness of transliterations. We asked a native speaker of English with good knowledge of Arabic to decide whether any given transliteration is correct or not. This humanbased evaluation is done for both the transliterations provided by the human translators and by our transliteration system. The human subject was presented with the names in the Arabic script, their gold-standard transliterations, and the transliteration that we are evaluating. For our transliteration algorithm, the human subject was provided with the top 20 transliteration candidates as well. The accuracy of the human translator based on the human-subjective evaluation is shown in Table 10. The accuracy of our transliteration models based on the human-subjective evaluation is shown in Table 11. The human translator's accuracy based on the human-subjective evaluation was higher than the exact-matching accuracy by about 11%. Most of the increase came from the forward-transliteration of Arab names. This was expected because for Arab names, typically many variant transliterations are acceptable. This was also reflected on the humansubjective evaluation of our spelling-based model. However, the accuracy of our phonetic-based model remains almost the same as in the case of the exactmatching evaluation. This is because names that can be found in the dictionary have only a single spelling that for the most part agrees with our gold-standard. Also, most of the names in the dictionary are English names and with English names the human evaluator was rigid, mostly accepting only the exact-matching spelling.
9 Discussion. We have presented and evaluated a transliteration algorithm using phonetic-based and spelling-based nation on the development and blind test sets by category. The evaluation is based on human-subjective evaluation. models. This algorithm is most accurate on backtransliterating English names. The reason for this is that most names in the dictionary are of English origin. Hence, the language model was mostly trained on English names. One way to improve transliterations of non-English names is to train the language model on a list of non-English names in addition to the dictionary names. Our current models do not deal with the issue of metathesis (e.g., metathesis of v and r between the spelling and the pronunciation of the name Favre) in person names across languages. Metathesis in person names into Arabic is often a result of wrong transliterations by the person who transliterated in the original name in Arabic. For example, the name Dostoevsky was found in our Arabic corpus transliterated as dystwyfsky&quot; and dystwyfksy&quot; (a metathesis of k and s); the name Ordzhonikidze was found transliterated as cirdjion ykydzy&quot; and &quot; Si ..Ati;.‹. ; cirdjyk yrt ydzt&quot; (a metathesis of k and n). This causes incorrect transliterations of theses names by our system. The transliteration accuracy on the blind test set for both our system and the human translator is significantly higher than the development test set. This is because the blind set is mostly of highly frequent, prominent politicians; whereas the development set contains also names of writers and less common political figures and hence are less likely to be in our unigram language model (and our pronunciation dictionary in the case of the phonetic-based model).