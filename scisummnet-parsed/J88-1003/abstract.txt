three previous efforts directed specifically to this problem. The first published effort is that of Klein and Simmons (1963), a simple system using suffix lists and limited frame rules. The second approach to lexical disambiguation is and Rubin (1971)), a system of several thousand context-frame rules. This algorithm was used to assign initial tags to the Brown Corpus. Third is the CLAWS system develto tag the (or LOB) Coris a corpus of British written English, parallel to the Brown Corpus. Parsing systems always encounter the problem of category ambiguity; but usually the focus of such systems is at other levels, making their responses less relevant for our purposes here. 1.1 KLEIN AND SIMMONS Klein and Simmons (1963) describe a method directed primarily towards the task of initial categorial tagging rather than disambiguation. Its primary goal is avoiding &quot;the labor of constructing a very large dictionary&quot; (p. 335); a consideration of greater import then than now. The Klein and Simmons algorithm uses a palette of 30 categories, and claims an accuracy of 90% in tagging. The algorithm first seeks each word in dictionaries of about 400 function words, and of about 1500 words which &quot;are exceptions to the computational rules used&quot; (p. 339). The program then checks for suffixes and special characters as clues. of all, frame tests applied. These work on scopes bounded by unambiguous words, as do later algorithms. However, Klein and Simmons impose an explicit limit of three ambiguous words in a row. For such ambiguous words, the pair of unambiguous categories bounding it is mapped into a list. The list includes all known sequences of tags occurring between the particular bounding tags; all such sequences of the correct length become candidates. The program then matches the candidate sequences against the ambiguities remaining from earlier steps of the algorithm. When only one sequence is possible, disambiguation is successful. The samples used for calibration and testing were limited. First, Klein and Simmons (1963) performed &quot;hand analysis of a sample [size unspecified] of Golden Grammatical Category Disambiguation by Statistical Optimization Book Encyclopedia text&quot; (p. 342). Later, &quot;[w]hen it was run on several pages from that encyclopedia, it correctly and unambiguously tagged slightly over 90% of the words&quot; (p. 344). Further tests were run on small from the Americana from Scientific American. Klein and Simmons (1963) assert that &quot;[o]riginal fears that sequences of four or more unidentified parts of speech would occur with great frequency were not substantiated in fact&quot; (p. 3). This felicity, however, is an artifact. First, the relatively small set of categories reduces ambiguity. Second, a larger sample would reveal both (a) low-frequency ambiguities and (b) many long spans, as discussed below. 1.2 GREENE AND RUBIN (TAGGIT) Greene and Rubin (1971) developed TAGGIT for tagging the Brown Corpus. The palette of 86 tags that TAGGIT uses has, with some modifications, also been used in both CLAWS and VOLSUNGA. The rationale underlying the choice of tags is described on pages 3-21 of Greene and Rubin (1971). Francis and Kucera (1982) report that this algorithm correctly tagged approxithe million words in the Brown Corpus (the tagging was then completed by human post-editors). Although this accuracy is substantially lower than that reported by Klein and Simmons, it should be remembered that Greene and Rubin were the first to attempt so large and varied a sample. TAGGIT divides the task of category assignment into initial (potentially ambiguous) tagging, and disambiguation. Tagging is carried out as follows: first, the program consults an exception dictionary of about 3,000 words. Among other items, this contains all known closed-class words. It then handles various special cases, such as words with initial &quot;$&quot;, contractions, special symbols, and capitalized words. The word's ending is then checked against a suffix list of about 450 strings. The lists were derived from lexicostatistics of the Brown Corpus. If TAGGIT has not assigned some tag(s) after these several steps, &quot;the word is tagged NN, VB, or JJ [that is, as being three-ways ambiguous], in order that the disambiguation routine may have something to work with&quot; (Greene and Rubin (1971), p. 25). After tagging, TAGGIT applies a set of 3300 context frame rules. Each rule, when its context is satisfied, has the effect of deleting one or more candidates from the list of possible tags for one word. If the number of candidates is reduced to one, disambiguation is considered successful subject to human post-editing. Each rule can include a scope of up to two unambiguous words on each side of the ambiguous word to which the rule is being applied. This constraint was determined as follows: In order to create the original inventory of Context Frame Tests, a 900-sentence subset of the Brown University Corpus was tagged. . . and its ambiguities were resolved manually; then a program was run 32 Computational Linguistics, Volume 14, Number 1, Winter 1988 Steven J. DeRose Grammatical Category Disambiguation by Statistical Optimization which produced and sorted all possible Context Frame Rules which would have been necessary to perform this disambiguation automatically. The rules generated were able to handle up to three consecutive ambiguous words preceded and followed by two non-ambiguous words [a constraint similar to Klein and Simmons']. However, upon examination of these rules, it was found that a sequence of two or three ambiguities rarely occurred more than once in a given context. Consequently, a decision was made to examine only one ambiguity at a time with up to two unambiguously tagged words on either side. The first rules created were the results of informed intuition (Greene and Rubin (1972), p. 32). 1.3 CLAWS Marshall (1983, p. 139) describes the LOB Corpus tagging algorithm, later named CLAWS (Booth (1985)), as &quot;similar to those employed in the TAGGIT program&quot;. The tag set used is very similar, but somewhat larger, at about 130 tags. The dictionary used is derived from the tagged Brown Corpus, rather than from the untagged. It contains 7000 rather than 3000 entries, and 700 rather than 450 suffixes. CLAWS treats plural, possessive, and hyphenated words as special cases for purposes of initial tagging. The LOB researchers began by using TAGGIT on parts of the LOB Corpus. They noticed that While less than 25% of TAGGIT's context frame rules are concerned with only the immediately preceding or succeeding word. . . these rules were applied in about 80% of all attempts to apply rules. This relative overuse of minimally specified contexts indicated that exploitation of the relationship between successive tags, coupled with a mechanism that would be applied throughout a sequence of ambiguous words, would produce a more accurate and effective method of word disambiguation (Marshall (1983), p. 141). The main innovation of CLAWS is the use of a matrix probabilities, the relative likelihood of co-occurrence of all ordered pairs of tags. This matrix can be mechanically derived from any pre-tagged corpus. CLAWS used &quot;[a] large proportion of the Brown Corpus&quot;, 200,000 words (Marshall (1983), pp. 141, 150). The ambiguities contained within a span of ambiguous words define a precise number of complete sets of mappings from words to individual tags. Each such of tags is called a path is composed of a number of tag collocations, and each such collocation has a probability which may be obtained from the collocation matrix. One may thus approximate each path's probability by the product of the probabilities of all its collocations. Each path corresponds to a unique assignment of tags to all words within a span. paths constitute a network, the path of maximal probability may be taken to contain the &quot;best&quot; tags. (1983) states that CLAWS the most probable sequence of tags, and in the majority of cases the correct tag for each individual word corresponds to the associated tag in the most probable sequence of tags&quot; (p. 142). But a more detailed examination of the Pascal code for CLAWS revealed that CLAWS has a more complex definition of &quot;most probable sequence&quot; than one might expect. A probability called &quot;SUMSUCCPROBS&quot; is predicated of each word. SUMSUCCPROBS is calculated by looping through all tags for the words immediately preceding, at, and following a word; for each tag triple, an increment is added, defined by: DownGrade(GetSucc(Tag2, Tag3), TagMark) * Get3SeqFactor(Tag1, Tag2, Tag3) the collocational probability of a tag either 1, or a special value the tag-triple list described below. the value of accordance with RTPs as described below. The CLAWS documentation describes SUMSUCC- PROBS as &quot;the total value of all relationships between the tags associated with this word and the tags associated with the next word. . . [found by] simulating all accesses to SUCCESSORS and ORDER2VALS which will be made. . . .&quot; The probability of each node of the span network (or rather, tree) is then calculated in the following way as a tree representing all paths through which the span network is built: = currenttag), TagMark) * Get3SeqFactor(. . .)) = PROB * (predecessor's It appears that the goal is to make each tag's probabe the summed probability of passing through it. At the final word of a span, pointers are followed back up the chosen path, and tags are chosen en route. We will see below that a simpler definition of optimal path is possible; nevertheless, there are several advantages of this general approach over previous ones. First, spans of unlimited length can be handled (subject to machine resources). Although earlier researchers (Klein and Simmons, Greene and Rubin) have suggested that spans of length over 5 are rare enough to be of little concern, this is not the case. The number of spans of a given length is a function of that length and the corpus size; so long spans may be obtained merely by examining more text. The total numbers of spans in the Brown Corpus, for each length from 3 to 19, are: 397111, 143447, 60224, 26515, 11409,5128, 2161, 903, 382, 161, 58, 29, 14, 6, 1, 0, 1. Graphing the logarithms Computational Linguistics, Volume 14, Number 1, Winter 1988 33 Steven J. DeRose Grammatical Category Disambiguation by Statistical Optimization of these quantities versus the span length for each, produces a near-perfect straight line. Second, a precise mathematical definition is possible for the fundamental idea of CLAWS. Whereas earlier efforts were based primarily on ad hoc or subjectively determined sets of rules and descriptions, and employed substantial exception dictionaries, this algorithm requires no human intervention for set-up; it is a systematic process. Third, the algorithm is quantitative and analog, rather than artificially discrete. The various tests and employed by earlier algorithms enforced absolute constraints on particular tags or collocations of tags. Here relative probabilities are weighed, and a series of very likely assignments can make possible a particular, a priori unlikely assignment with which they are associated. In addition to collocational probabilities, CLAWS also takes into account one other empirical quantity: Tags associated with words. . . can be with a marker @ or %; @ indicates that the tag is infrequently the correct tag for the associated word(s) (less than 1 in 10 occasions), % indicates is highly improbable. . . (less than 1 in 100 oc- . . . The word disambiguation program currently uses these markers top devalue values when retrieving a value from the matrix, @ results in the value being halved, % in the value being divided by eight (Marshall (1983), p. 149). Thus, the independent probability of each possible tag for a given word influences the choice of an optimal Such probabilities will be referred to as Probabilities, Other features have been added to the basic algorithm. For example, a good deal of suffix analysis is used in initial tagging. Also, the program filters its output, considering itself to have failed if the optimal tag assignment for a span is not &quot;more than 90% probable&quot;. cases it reorders tags rather than actually disambiguating. On long spans this criterion is effectively more stringent than on short spans. A more significant addition to the algorithm is that a number of tag triples associated with a have been introduced which may either upgrade or downgrade values in the tree computed from the one-step matrix. For example, the triple [1] [2] adverb [3] past-tense-verb has been assigned a factor which downgrades a sequence containing this triple compared with a competing of [1] 'be' [2] adverb [3]-past-participle/adjective, on the basis that after a form of 'be', past participles and adjectives are more likely than a past tense verb (Marshall (1983), p. 146). A similar move was used near conjunctions, for which the words on either side, though separated, are more closely correlated to each other than either is to the conjunction itself (Marshall (1983), pp. 146-147). For example, a verb/noun ambiguity conjoined to a verb should probably be taken as a verb. Leech, Garside, and Atwell (1983, p. 23) describe &quot;IDIOMTAG&quot;, which is applied after initial tag assignment and before disambiguation. It was developed as a means of dealing with sequences which would otherwise cause diffifor the automatic tagging. . . . for example, that tagged as a single conjunction. . . . Tagging Program. . . can look at any combination of words and tags, with or without intervening words. It can delete tags, add tags, or change the probability of tags. Although this program might to be an hoc it is worth bearing in that any fully automatic language analysis syshas to come to with problems of lexical idiosyncrasy. IDIOMTAG also accounts for the fact that the probability of a verb being a past participle, and not simply past, is greater when the following word is &quot;by&quot;, as opposed to other prepositions. Certain cases of this sort may be soluble by making the collocational matrix distinguish classes of ambiguities—this question is being pursued. Approximately 1% of running text is tagged by IDIOMTAG (letter, G. N. Leech to Henry Kucera, June 7, 1985; letter, E. S. Atwell to Henry Kucera, June 20, 1985). Marshall notes the possibility of consulting a complete three-dimensional matrix of collocational probabilities. Such a matrix would map ordered triples of tags into the relative probability of occurrence of each such triple. Marshall points out that such a table would be too large for its probable usefulness. The author has proa table based upon more 85% of the Brown Corpus; it occupies about 2 megabytes (uncompressed). Also, the mean number of examples per triple is very low, thus decreasing accuracy. CLAWS has been applied to the entire LOB Corpus with an accuracy of &quot;between 96% and 97%&quot; (Booth (1985), p. 29). Without the idiom list, the algorithm was 94% accurate on a sample of 15,000 words (Marshall (1983)). Thus, the pre-processor tagging of 1% of all tokens resulted in a 3% change in accuracy; those particular assignments must therefore have had a substantial effect upon their context, resulting in changes of two other words for every one explicitly tagged. But CLAWS is timeand storage-inefficient in the extreme, and in some cases a fallback algorithm is employed to prevent running out of memory, as was discovered by examining the Pascal program code. How often the fallback is employed is not known, nor is it known what effect its use has on overall accuracy. Since CLAWS calculates the probability of every path, it operates in time and space proportional to the product of all the degrees of ambiguity of the words in the span. Thus, the time is exponential (and hence Non-Polynomial) in the span length. For the longest span in the Brown Corpus, of length 18, the number of paths examined would be 1,492,992. 34 Computational Linguistics, Volume 14, Number 1, Winter 1988 Steven J. DeRose Grammatical Category Disambiguation by Statistical Optimization LINEAR-TIME ALGORITHM The algorithm described here depends on a similar empirically-derived transitional probability matrix to that of CLAWS, and has a similar definition of &quot;optimal path&quot;. The tagset is larger than TAGGIT's, though smaller than CLAWS', containing 97 tags. The ultimate assignments of tags are much like those of CLAWS. However, it embodies several substantive changes. Those features that can be algorithmically defined have been used to the fullest extent. Other add-ons have been minimized. The major differences are outlined below. First, the optimal path is defined to be the one whose component collocations multiply out to the highest probability. The more complex definition applied by using the sum of all paths at of the network, is not used. Second, VOLSUNGA overcomes the Non-Polynomial complexity of CLAWS. Because of this change, it is never necessary to resort to a fallback algorithm, and the program is far smaller. Furthermore, testing the algorithm on extensive texts is not prohibitively costly. Third, VOLSUNGA implements Relative Tag Probabilities (RTPs) in a more quantitative manner, based upon counts from the Brown Corpus. Where CLAWS scales probabilities by 1/2 for RTP < 0.1 (i.e., where less than 10% of the tokens for an ambiguous word are in the category in question), and by 1/8 for p < 0.01, VOLSUNGA uses the RTP value itself as a factor in the equation which defines probability. Fourth, VOLSUNGA uses no tag triples and no idioms. Because of this, manually constructing specialcase lists is not necessary. These methods are useful in certain cases, as the accuracy figures for CLAWS show; but the goal here was to measure the accuracy of a wholly algorithmic tagger on a standard corpus.