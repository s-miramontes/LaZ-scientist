PK F-score ❳ c the set by the MEMM tagger that scans the input from left to right and the last column is the results after the Transformation- Based Learner is applied. The results show that using Transformation-Based learning only give rise to slight improvements. It seems that the bidirectional approach does not help much for the LMR tagging. Therefore, we only submitted the results of our leftto-right MEMM tagger, retrained on the entire training sets, as our official results. F-score MEMM MEMM+TBL AS 0.9595 0.9603 HK 0.9143 N/A PK 0.9391 0.9398 Table 2: F-score on development data The results on the official test data is similar to we have got on our except that the F-score on the Beijing Univ. corpus is over 2 lower in absolute accuracy than what we expected. The reason is that in the training data of Beijing University corpus, all the numbers are encoded in GBK, while in the test data many numbers are encoded in ASCII, which are unknown to our tagger. With this problem fixed, the results of the official test data are compatible with the results on However, we have withdrawn our segmentation results on the Beijing University corpus. corpus R P F AS 0.961 0.958 0.959 0.729 0.966 HK 0.917 0.915 0.916 0.670 0.936 Table 3: Official Bakeoff Outcome 4 Conclusions and Future Work Our closed track experiments on the first Sighan Bakeoff data show that the LMR algorithm produces promising results. Our system ranks the second when tested on the Academia Sinica corpus and third on the Hong Kong City University corpus. In the future, we will try to incorporate a large word list into our tagger to test its performance on open track experiments. Its high accuracy on makes it a good candidate as a general purpose segmenter. References E. Brill. 1995. Transformation-based error-driven learning and natural language processing: A case study part-of-speech tagging. 21(4):543–565. C. K. Fan and W. H. Tsai. 1988. Automatic word identification in chinese sentences by the relaxation tech- Processing of Chinese and Oriental 4(1):33–56. Kok-Wee Gan, Martha Palmer, and Kim-Teng Lua. 1996. A statistically emergent approach for language processing: Application to modeling context effects in chinese word boundary perception. Com- 22(4):531–53. J. Lafferty, A. McCallum, and F. Pereira. 2001. Conditional random fields: Probabilistic models for stgmenand labeling sequence data. In of G. Ngai and R. Florian. 2001. Transformation-based in the fast lane. In of NAACLpages 40–47. Adwait Ratnaparkhi. 1996. A maximum entropy part-oftagger. In of the Empirical Methin Natural Language Processing University of Pennsylvania. L. Shen and A. K. Joshi. 2003. A SNoW based supertagwith application to NP chunking. In R. Sproat, Chilin Shih, William Gale, and Nancy Chang. 1996. A stochastic finite-state word-segmentation for chinese. 22(3):377–404. H. van Halteren, J. Zavrel, and W. Daelmans. 1998. Improving data driven wordclass tagging by system com- In of COLING-ACL Andi Wu. 2003. Customizable segmentation of morderived words in chinese. and Chinese Language Nianwen Xue. 2003. Chinese word segmentation as tagging. Linguistics and